# handlers/voice_handler.py

import os
import io
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes, MessageHandler, filters, CommandHandler, CallbackQueryHandler
from openai import OpenAI
from database import db
from config import (
    VOICE_TO_TEXT_COST, TEXT_TO_VOICE_COST, MAX_VOICE_DURATION,
    AVAILABLE_VOICES, MESSAGE_COST
)

def register_handlers(application, openai_client: OpenAI, supabase):
    
    async def voice_message_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è - —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏."""
        user_id = update.effective_user.id
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å
        current_credits = await db.get_user_credits(supabase, user_id)
        if current_credits < VOICE_TO_TEXT_COST:
            await update.message.reply_text(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫—Ä–µ–¥–∏—Ç–æ–≤ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏.\n"
                f"–ù—É–∂–Ω–æ: {VOICE_TO_TEXT_COST} –∫—Ä–µ–¥–∏—Ç–æ–≤, —É –≤–∞—Å: {current_credits}"
            )
            return
        
        voice = update.message.voice
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        if voice.duration > MAX_VOICE_DURATION:
            await update.message.reply_text(
                f"‚ùå –ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ!\n"
                f"–ú–∞–∫—Å–∏–º—É–º: {MAX_VOICE_DURATION} —Å–µ–∫—É–Ω–¥, —É –≤–∞—Å: {voice.duration} —Å–µ–∫—É–Ω–¥"
            )
            return
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        voice_settings = await db.get_user_voice_settings(supabase, user_id)
        language = voice_settings.get('voice_language', 'ru')
        
        await update.message.reply_text("üéôÔ∏è –†–∞—Å–ø–æ–∑–Ω–∞—é —Ä–µ—á—å...")
        
        try:
            # –°–∫–∞—á–∏–≤–∞–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            voice_file = await context.bot.get_file(voice.file_id)
            voice_bytes = io.BytesIO()
            await voice_file.download_to_memory(voice_bytes)
            voice_bytes.seek(0)
            voice_bytes.name = "voice.ogg"  # OpenAI —Ç—Ä–µ–±—É–µ—Ç –∏–º—è —Ñ–∞–π–ª–∞
            
            # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ä–µ—á—å —á–µ—Ä–µ–∑ OpenAI Whisper
            transcript = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=voice_bytes,
                language=language,
                response_format="text"
            )
            
            # –°–ø–∏—Å—ã–≤–∞–µ–º –∫—Ä–µ–¥–∏—Ç—ã
            await db.deduct_user_credits(supabase, user_id, VOICE_TO_TEXT_COST)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            await db.increment_voice_stats(supabase, user_id, "received")
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
            await update.message.reply_text(
                f"üéôÔ∏è **–†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:**\n{transcript}\n\n"
                f"üí∞ –°–ø–∏—Å–∞–Ω–æ {VOICE_TO_TEXT_COST} –∫—Ä–µ–¥–∏—Ç–æ–≤",
                parse_mode='Markdown'
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –æ—Ç–≤–µ—á–∞—Ç—å –≥–æ–ª–æ—Å–æ–º
            if voice_settings.get('voice_enabled', False):
                await generate_voice_response(update, context, openai_client, supabase, transcript)
            else:
                # –û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ AI
                await process_text_for_ai(update, context, openai_client, supabase, transcript)
                
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ —Ä–µ—á–∏: {e}")
            await update.message.reply_text(
                "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.\n"
                "–ö—Ä–µ–¥–∏—Ç—ã –Ω–µ –±—ã–ª–∏ —Å–ø–∏—Å–∞–Ω—ã."
            )

    async def generate_voice_response(update: Update, context: ContextTypes.DEFAULT_TYPE, 
                                    openai_client: OpenAI, supabase, text: str):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≥–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç –Ω–∞ —Ç–µ–∫—Å—Ç."""
        user_id = update.effective_user.id
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        current_credits = await db.get_user_credits(supabase, user_id)
        if current_credits < TEXT_TO_VOICE_COST + MESSAGE_COST:
            await update.message.reply_text(
                f"‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫—Ä–µ–¥–∏—Ç–æ–≤ –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞.\n"
                f"–ù—É–∂–Ω–æ: {TEXT_TO_VOICE_COST + MESSAGE_COST} –∫—Ä–µ–¥–∏—Ç–æ–≤, —É –≤–∞—Å: {current_credits}"
            )
            return
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –æ—Ç AI
            user_data = await db.get_user_data(supabase, user_id)
            from config import CHAT_MODES
            system_prompt = CHAT_MODES.get(user_data['mode'], "–¢—ã ‚Äî –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.")
            history = await db.get_user_history(supabase, user_id)
            
            messages_for_api = [
                {"role": "system", "content": system_prompt}
            ] + history + [
                {"role": "user", "content": text}
            ]
            
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç AI
            response = openai_client.chat.completions.create(
                model=user_data['model'],
                messages=messages_for_api,
                max_tokens=500  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
            )
            
            ai_response = response.choices[0].message.content
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç
            voice_settings = await db.get_user_voice_settings(supabase, user_id)
            selected_voice = voice_settings.get('selected_voice', 'alloy')
            
            await update.message.reply_text("üîä –ì–µ–Ω–µ—Ä–∏—Ä—É—é –≥–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç...")
            
            # –°–æ–∑–¥–∞–µ–º TTS —á–µ—Ä–µ–∑ OpenAI
            tts_response = openai_client.audio.speech.create(
                model="tts-1",
                voice=selected_voice,
                input=ai_response,
                response_format="mp3"
            )
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ BytesIO –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏
            audio_data = io.BytesIO(tts_response.content)
            audio_data.name = "voice_response.mp3"
            audio_data.seek(0)
            
            # –°–ø–∏—Å—ã–≤–∞–µ–º –∫—Ä–µ–¥–∏—Ç—ã
            await db.deduct_user_credits(supabase, user_id, TEXT_TO_VOICE_COST + MESSAGE_COST)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
            await db.add_message_to_history(supabase, user_id, "user", text)
            await db.add_message_to_history(supabase, user_id, "assistant", ai_response)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            await db.increment_voice_stats(supabase, user_id, "sent")
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            await update.message.reply_voice(
                voice=audio_data,
                caption=f"üîä –ì–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç\nüí∞ –°–ø–∏—Å–∞–Ω–æ {TEXT_TO_VOICE_COST + MESSAGE_COST} –∫—Ä–µ–¥–∏—Ç–æ–≤"
            )
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {e}")
            await update.message.reply_text(
                "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç.\n"
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ä–µ–∂–∏–º."
            )

    async def process_text_for_ai(update: Update, context: ContextTypes.DEFAULT_TYPE,
                                openai_client: OpenAI, supabase, text: str):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ AI (–æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç)."""
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∏–∑ message_handlers
        from handlers.message_handlers import chat_with_ai
        
        # –°–æ–∑–¥–∞–µ–º —Ñ–µ–π–∫–æ–≤—ã–π update —Å —Ç–µ–∫—Å—Ç–æ–º
        class FakeMessage:
            def __init__(self, text):
                self.text = text
        
        fake_update = type('obj', (object,), {
            'effective_chat': type('obj', (object,), {'id': update.effective_chat.id})(),
            'message': FakeMessage(text)
        })()
        
        await chat_with_ai(fake_update, context, openai_client, supabase)

    # --- –ö–û–ú–ê–ù–î–´ –î–õ–Ø –ù–ê–°–¢–†–û–ô–ö–ò –ì–û–õ–û–°–ê ---

    async def voice_settings_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–µ–Ω—é –Ω–∞—Å—Ç—Ä–æ–µ–∫ –≥–æ–ª–æ—Å–∞ (–¥–æ—Å—Ç—É–ø–Ω–æ —á–µ—Ä–µ–∑ /voice)."""
        user_id = update.effective_user.id
        voice_settings = await db.get_user_voice_settings(supabase, user_id)
        voice_stats = await db.get_voice_stats(supabase, user_id)
        
        # –ù–∞–π–¥–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –≥–æ–ª–æ—Å–∞
        current_voice_name = "–ù–µ –Ω–∞–π–¥–µ–Ω"
        for name, voice_id in AVAILABLE_VOICES.items():
            if voice_id == voice_settings.get('selected_voice'):
                current_voice_name = name
                break
        
        status = "üîä –í–∫–ª—é—á–µ–Ω—ã" if voice_settings.get('voice_enabled') else "üîá –í—ã–∫–ª—é—á–µ–Ω—ã"
        
        settings_text = (
            f"üéôÔ∏è **–ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π**\n\n"
            f"**–°—Ç–∞—Ç—É—Å:** {status}\n"
            f"**–¢–µ–∫—É—â–∏–π –≥–æ–ª–æ—Å:** {current_voice_name}\n"
            f"**–Ø–∑—ã–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:** {voice_settings.get('voice_language', 'ru').upper()}\n\n"
            f"üìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:**\n"
            f"‚Ä¢ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –≥–æ–ª–æ—Å–æ–≤—ã—Ö: {voice_stats['sent']}\n"
            f"‚Ä¢ –ü–æ–ª—É—á–µ–Ω–æ –≥–æ–ª–æ—Å–æ–≤—ã—Ö: {voice_stats['received']}\n\n"
            f"üí∞ **–°—Ç–æ–∏–º–æ—Å—Ç—å:**\n"
            f"‚Ä¢ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏: {VOICE_TO_TEXT_COST} –∫—Ä–µ–¥–∏—Ç–æ–≤\n"
            f"‚Ä¢ –ì–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç: {TEXT_TO_VOICE_COST} –∫—Ä–µ–¥–∏—Ç–æ–≤\n\n"
            f"‚ÑπÔ∏è –î–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ /menu ‚Üí üéôÔ∏è –ì–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è"
        )
        
        await update.message.reply_text(settings_text, parse_mode='Markdown')

    # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –∫–æ–º–∞–Ω–¥—É
    application.add_handler(MessageHandler(filters.VOICE, voice_message_handler))
    application.add_handler(CommandHandler("voice", voice_settings_command))