# handlers/voice_handler.py

import os
import io
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ContextTypes, MessageHandler, filters, CommandHandler, CallbackQueryHandler
from openai import OpenAI
from database import db
from config import (
    VOICE_TO_TEXT_COST, TEXT_TO_VOICE_COST, MAX_VOICE_DURATION,
    AVAILABLE_VOICES, MESSAGE_COST
)
from translations import get_text

def register_handlers(application, openai_client: OpenAI, supabase):
    
    async def voice_message_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è - —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏."""
        user_id = update.effective_user.id
        print(f"üéôÔ∏è –ü–û–õ–£–ß–ï–ù–û –ì–û–õ–û–°–û–í–û–ï –°–û–û–ë–©–ï–ù–ò–ï –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
        
        # –ü–æ–ª—É—á–∞–µ–º —è–∑—ã–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_language = await db.get_user_language(supabase, user_id)
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω—É–∂–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫—Ä–µ–¥–∏—Ç–æ–≤
        voice_settings = await db.get_user_voice_settings(supabase, user_id)
        voice_enabled = voice_settings.get('voice_enabled', False)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω—É–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫—Ä–µ–¥–∏—Ç–æ–≤
        if voice_enabled:
            # –ï—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω—ã –≥–æ–ª–æ—Å–æ–≤—ã–µ –æ—Ç–≤–µ—Ç—ã: —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ + –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –≥–æ–ª–æ—Å–∞ + —Å–æ–æ–±—â–µ–Ω–∏–µ AI
            required_credits = VOICE_TO_TEXT_COST + TEXT_TO_VOICE_COST + MESSAGE_COST
            operation_description = get_text(user_language, 'voice_response_cost', cost=required_credits).replace('‚Ä¢ ', '').replace(' –∫—Ä–µ–¥–∏—Ç–æ–≤ (—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ + —Å–∏–Ω—Ç–µ–∑ + AI)', '').replace(' credits (recognition + synthesis + AI)', '').replace(' kredyt√≥w (rozpoznawanie + synteza + AI)', '')
        else:
            # –ï—Å–ª–∏ –≥–æ–ª–æ—Å–æ–≤—ã–µ –æ—Ç–≤–µ—Ç—ã –≤—ã–∫–ª—é—á–µ–Ω—ã: —Ç–æ–ª—å–∫–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
            required_credits = VOICE_TO_TEXT_COST
            operation_description = get_text(user_language, 'voice_recognition_cost', cost=required_credits).replace('‚Ä¢ ', '').replace(' –∫—Ä–µ–¥–∏—Ç–æ–≤', '').replace(' credits', '').replace(' kredyt√≥w', '')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å
        current_credits = await db.get_user_credits(supabase, user_id)
        print(f"üí∞ –ë–∞–ª–∞–Ω—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {current_credits} –∫—Ä–µ–¥–∏—Ç–æ–≤ (–Ω—É–∂–Ω–æ: {required_credits})")
        
        if current_credits < required_credits:
            if voice_enabled and current_credits >= VOICE_TO_TEXT_COST:
                # –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è, –Ω–æ –Ω–µ –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                error_message = get_text(
                    user_language, 'insufficient_credits_voice_full',
                    current=current_credits,
                    needed=required_credits,
                    recognition_cost=VOICE_TO_TEXT_COST
                )
                await update.message.reply_text(error_message, parse_mode='Markdown')
                return
            else:
                # –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–∂–µ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
                error_message = get_text(
                    user_language, 'insufficient_credits_voice_recognition',
                    operation=operation_description,
                    current=current_credits,
                    needed=required_credits
                )
                await update.message.reply_text(error_message, parse_mode='Markdown')
                return
        
        voice = update.message.voice
        print(f"üéµ –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ: {voice.duration} —Å–µ–∫—É–Ω–¥")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        if voice.duration > MAX_VOICE_DURATION:
            print(f"‚ùå –ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ: {voice.duration} > {MAX_VOICE_DURATION}")
            error_message = get_text(
                user_language, 'voice_too_long',
                max_duration=MAX_VOICE_DURATION,
                duration=voice.duration
            )
            await update.message.reply_text(error_message)
            return
        
        language = voice_settings.get('voice_language', 'ru')
        print(f"üåç –Ø–∑—ã–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {language}")
        
        processing_message = get_text(user_language, 'recognizing_speech')
        await update.message.reply_text(processing_message)
        
        try:
            print("üì• –°–∫–∞—á–∏–≤–∞—é –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")
            # –°–∫–∞—á–∏–≤–∞–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            voice_file = await context.bot.get_file(voice.file_id)
            voice_bytes = io.BytesIO()
            await voice_file.download_to_memory(voice_bytes)
            voice_bytes.seek(0)
            voice_bytes.name = "voice.ogg"  # OpenAI —Ç—Ä–µ–±—É–µ—Ç –∏–º—è —Ñ–∞–π–ª–∞
            
            print("ü§ñ –û—Ç–ø—Ä–∞–≤–ª—è—é –≤ OpenAI Whisper...")
            # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ä–µ—á—å —á–µ—Ä–µ–∑ OpenAI Whisper
            transcript = openai_client.audio.transcriptions.create(
                model="whisper-1",
                file=voice_bytes,
                language=language,
                response_format="text"
            )
            
            print(f"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {transcript}")
            
            # –°–ø–∏—Å—ã–≤–∞–µ–º –∫—Ä–µ–¥–∏—Ç—ã –∑–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
            await db.deduct_user_credits(supabase, user_id, VOICE_TO_TEXT_COST)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            await db.increment_voice_stats(supabase, user_id, "received")
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
            recognition_message = get_text(
                user_language, 'recognized_text',
                text=transcript,
                cost=VOICE_TO_TEXT_COST
            )
            await update.message.reply_text(recognition_message, parse_mode='Markdown')
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –æ—Ç–≤–µ—á–∞—Ç—å –≥–æ–ª–æ—Å–æ–º
            if voice_enabled:
                print("üîä –ì–µ–Ω–µ—Ä–∏—Ä—É—é –≥–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç...")
                await generate_voice_response(update, context, openai_client, supabase, transcript, user_language)
            else:
                print("üí¨ –ì–µ–Ω–µ—Ä–∏—Ä—É—é —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç...")
                # –û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç —á–µ—Ä–µ–∑ AI
                await process_text_for_ai(update, context, openai_client, supabase, transcript, user_language)
                
        except Exception as e:
            print(f"‚ùå –û–®–ò–ë–ö–ê –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏ —Ä–µ—á–∏: {e}")
            import traceback
            traceback.print_exc()
            error_message = get_text(user_language, 'voice_recognition_error')
            await update.message.reply_text(error_message)

    async def generate_voice_response(update: Update, context: ContextTypes.DEFAULT_TYPE, 
                                    openai_client: OpenAI, supabase, text: str, user_language: str):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≥–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç –Ω–∞ —Ç–µ–∫—Å—Ç."""
        user_id = update.effective_user.id
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç –æ—Ç AI
            user_data = await db.get_user_data(supabase, user_id)
            from config import CHAT_MODES
            system_prompt = CHAT_MODES.get(user_data['mode'], "–¢—ã ‚Äî –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.")
            history = await db.get_user_history(supabase, user_id)
            
            messages_for_api = [
                {"role": "system", "content": system_prompt}
            ] + history + [
                {"role": "user", "content": text}
            ]
            
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç AI
            response = openai_client.chat.completions.create(
                model=user_data['model'],
                messages=messages_for_api,
                max_tokens=500  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
            )
            
            ai_response = response.choices[0].message.content
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç
            voice_settings = await db.get_user_voice_settings(supabase, user_id)
            selected_voice = voice_settings.get('selected_voice', 'alloy')
            
            generating_message = get_text(user_language, 'generating_voice_response')
            await update.message.reply_text(generating_message)
            
            # –°–æ–∑–¥–∞–µ–º TTS —á–µ—Ä–µ–∑ OpenAI
            tts_response = openai_client.audio.speech.create(
                model="tts-1",
                voice=selected_voice,
                input=ai_response,
                response_format="mp3"
            )
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ BytesIO –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏
            audio_data = io.BytesIO(tts_response.content)
            audio_data.name = "voice_response.mp3"
            audio_data.seek(0)
            
            # –°–ø–∏—Å—ã–≤–∞–µ–º –∫—Ä–µ–¥–∏—Ç—ã –∑–∞ TTS –∏ AI –æ—Ç–≤–µ—Ç
            total_cost = TEXT_TO_VOICE_COST + MESSAGE_COST
            await db.deduct_user_credits(supabase, user_id, total_cost)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
            await db.add_message_to_history(supabase, user_id, "user", text)
            await db.add_message_to_history(supabase, user_id, "assistant", ai_response)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            await db.increment_voice_stats(supabase, user_id, "sent")
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            caption = get_text(user_language, 'voice_response_caption', cost=total_cost)
            await update.message.reply_voice(
                voice=audio_data,
                caption=caption
            )
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {e}")
            error_message = get_text(user_language, 'voice_generation_error')
            await update.message.reply_text(error_message)

    async def process_text_for_ai(update: Update, context: ContextTypes.DEFAULT_TYPE,
                                openai_client: OpenAI, supabase, text: str, user_language: str):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ AI (–æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç)."""
        user_id = update.effective_user.id
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            user_data = await db.get_user_data(supabase, user_id)
            current_credits = await db.get_user_credits(supabase, user_id)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
            if current_credits < MESSAGE_COST:
                error_message = get_text(
                    user_language, 'insufficient_credits_voice_recognition',
                    operation=get_text(user_language, 'insufficient_credits_chat', cost=MESSAGE_COST).replace(f"–î–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω—É–∂–Ω–æ: {MESSAGE_COST}.", "–æ—Ç–≤–µ—Ç–∞ AI").replace(f"Need for response: {MESSAGE_COST}.", "AI response").replace(f"Potrzebujesz na odpowied≈∫: {MESSAGE_COST}.", "odpowiedzi AI"),
                    current=current_credits,
                    needed=MESSAGE_COST
                )
                await update.message.reply_text(error_message, parse_mode='Markdown')
                return
            
            # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
            from config import CHAT_MODES
            current_mode_name = user_data['mode']
            current_model = user_data['model']
            history = await db.get_user_history(supabase, user_id)
            system_prompt = CHAT_MODES.get(current_mode_name, "–¢—ã ‚Äî –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è API
            messages_for_api = [{"role": "system", "content": system_prompt}] + history + [{"role": "user", "content": text}]

            await context.bot.send_chat_action(chat_id=user_id, action='typing')
            
            # –ü–æ–ª—É—á–∞–µ–º –æ—Ç–≤–µ—Ç –æ—Ç AI
            response = openai_client.chat.completions.create(
                model=current_model, 
                messages=messages_for_api
            )
            ai_response_text = response.choices[0].message.content
            
            # –°–ø–∏—Å—ã–≤–∞–µ–º –∫—Ä–µ–¥–∏—Ç—ã –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
            await db.deduct_user_credits(supabase, user_id, MESSAGE_COST)
            await db.add_message_to_history(supabase, user_id, "user", text)
            await db.add_message_to_history(supabase, user_id, "assistant", ai_response_text)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç
            response_message = f"{ai_response_text}\n\nüí∞ {get_text(user_language, 'recognized_text', text='', cost=MESSAGE_COST).split('üí∞')[1].strip()}"
            await update.message.reply_text(response_message)
            
        except Exception as e:
            print(f"‚ùå –û–®–ò–ë–ö–ê –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {e}")
            import traceback
            traceback.print_exc()
            error_message = get_text(user_language, 'text_response_error')
            await update.message.reply_text(error_message)

    # --- –ö–û–ú–ê–ù–î–´ –î–õ–Ø –ù–ê–°–¢–†–û–ô–ö–ò –ì–û–õ–û–°–ê ---

    async def voice_settings_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–µ–Ω—é –Ω–∞—Å—Ç—Ä–æ–µ–∫ –≥–æ–ª–æ—Å–∞ (–¥–æ—Å—Ç—É–ø–Ω–æ —á–µ—Ä–µ–∑ /voice)."""
        user_id = update.effective_user.id
        user_language = await db.get_user_language(supabase, user_id)
        
        voice_settings = await db.get_user_voice_settings(supabase, user_id)
        voice_stats = await db.get_voice_stats(supabase, user_id)
        
        # –ù–∞–π–¥–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –≥–æ–ª–æ—Å–∞
        current_voice_name = "–ù–µ –Ω–∞–π–¥–µ–Ω"
        for name, voice_id in AVAILABLE_VOICES.items():
            if voice_id == voice_settings.get('selected_voice'):
                current_voice_name = name
                break
        
        status = get_text(user_language, 'voice_enabled') if voice_settings.get('voice_enabled') else get_text(user_language, 'voice_disabled')
        
        settings_text = (
            f"{get_text(user_language, 'voice_settings_title')}\n\n"
            f"{get_text(user_language, 'voice_status', status=status)}\n"
            f"{get_text(user_language, 'current_voice', voice=current_voice_name)}\n"
            f"{get_text(user_language, 'recognition_language', language=voice_settings.get('voice_language', 'ru').upper())}\n\n"
            f"{get_text(user_language, 'voice_statistics')}\n"
            f"{get_text(user_language, 'voice_sent', count=voice_stats['sent'])}\n"
            f"{get_text(user_language, 'voice_received', count=voice_stats['received'])}\n\n"
            f"{get_text(user_language, 'voice_costs')}\n"
            f"{get_text(user_language, 'voice_recognition_cost', cost=VOICE_TO_TEXT_COST)}\n"
            f"{get_text(user_language, 'voice_response_cost', cost=TEXT_TO_VOICE_COST)}\n\n"
            f"‚ÑπÔ∏è {get_text(user_language, 'voice_test_hint').replace('‚ÑπÔ∏è ', '')}"
        )
        
        await update.message.reply_text(settings_text, parse_mode='Markdown')

    # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –∫–æ–º–∞–Ω–¥—É
    application.add_handler(MessageHandler(filters.VOICE, voice_message_handler))
    application.add_handler(CommandHandler("voice", voice_settings_command))